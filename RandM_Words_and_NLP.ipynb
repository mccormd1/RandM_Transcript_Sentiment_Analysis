{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Natural Language Processing\n",
    "\n",
    "Natural Languae Processing (NLP) focuses on computer understanding of human language. The future of text-based NLP may include more accurate search, universal translation, summary of text, conversational coding, androids... etc.\n",
    "\n",
    "There are many many challenges that stand in the way of these things at the moment. A short list of these challenges include:\n",
    "1. Polysemy - words can have multiple meanings; which meaning is the correct one?\n",
    "2. Fluidity of syntax and grammar - what rules to use to break down a sentence?\n",
    "3. Errors - misspellings or incorrect grammar can derail brittle analysis\n",
    "3. Semantics - meaning can change on a word and sentence level\n",
    "4. Context - how much is plainly written and how much must be inferred?\n",
    "5. Evolution of language - rarely are languages in stasis.\n",
    "\n",
    "\n",
    "The Basic outline for NLP flows through four **very broad** tiers/categories of increasing scope and difficulty:\n",
    "1. Morphological processing - What are the discrete units (tokens) of meaning? in english it is relatively trivial as \"words\" are distinctly separated, however there are subwords. For example, \"incoherently\" has a prefix \"in-\", \"coherent\", and a suffix \"-ly\". each part changes the meaning and usage. Tokens can have multiple meanings (polysemy), and the exact meaning and type (e.g. noun, verb etc.) of a word may be ambiguous at this point. \n",
    "\n",
    "2. Syntax/Grammar processing - What is the structure of the sentence? Do the words interact correctly? By looking at the what tokens are in a string as well as what *order* they are in, we can determine relationships between tokens based on rules of definitions (lexicon) and syntax (grammar/structure). This processing can convert a sentence like \"The large cat chased the rat\"into a formal notation such as \"Article Adjective Noun Verb Article Noun\", or further into \"Noun-Phrase Verb Noun-Phrase\" (see Lkit pdf for tree viz). Grammar can disambiguate the meanings of \"brush\" in the sentences \"**Brush** your hair\" (verb) vs. \"Hand me the **brush**\" (noun).\n",
    "\n",
    "3. Semantic Analysis -  What is the meaning of a string (sentence) of tokens (words)? The relationship of words in the syntactic framework allows us to disambiguate the meaning of the words. Semantic analysis allows us to  in the sentence \"He put a carrot on the plate and then ate **it**\", we need semantics to determine what \"it\" is - in this case \"it\" is a carrot, not a plate.\n",
    "\n",
    "4. Pragmatic (contextual) analysis - What is the meaning with respect to the entire context? There are many phrases that are still ambiguous after semantic analysis, such as \"put the apple in the basket on the shelf.\", which can have two meanings:\n",
    " - put the apple which is *currently in the basket* on the shelf\n",
    " - put the apple into the basket which is *currently on the shelf*\n",
    "\n",
    "   Although this is a trivial example, the \"correct\" answer depends on the current state of the apple and basket, which may have been determined in previous sentences. Humor and sarcasm are extremely advanced forms of contextual understanding: \"Trump is definitely the best president ever\" can mean completely opposite things depending on who is saying it, and when they say it. It would require both understanding of the current state of a broad range of topics, as well as the history of the person saying it.\n",
    "\n",
    "A few interesting links that helped me create this document (as I am still learning!)\n",
    "\n",
    "[Algorithmia - What is NLP?](https://blog.algorithmia.com/introduction-natural-language-processing-nlp/)\n",
    "\n",
    "[Lkit NLP intro](https://www.scm.tees.ac.uk/isg/aia/nlp/NLP-overview.pdf) \n",
    "\n",
    "[Zareen Syed's slideshare](https://www.slideshare.net/zareen/challenges-in-nlp)\n",
    "\n",
    "[tutorialspoint intro to NLP](https://www.tutorialspoint.com/artificial_intelligence/artificial_intelligence_natural_language_processing.htm)\n",
    "\n",
    "[Analytics Vidhya guide to NLP](https://www.analyticsvidhya.com/blog/2017/01/ultimate-guide-to-understand-implement-natural-language-processing-codes-in-python/)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Important steps breakdown\n",
    "\n",
    "### Preprocessing (even more than before!!!)\n",
    "#### Remove Noise\n",
    "- remove scene action tagged sentences\n",
    "- remove language stopwords words such as \"is\", \"a\", \"this\". These are super common words that do not help in determining context of words.\n",
    "\n",
    "#### Lexicon Normalization\n",
    "- compressing multiple representations of the same word into one with stemming (strip suffixes)\n",
    "\n",
    "\n",
    "Statistical:\n",
    "word and sentence counts per character\n",
    "tf-idf: term frequency inverse document frequency. This finds the frequency of words in a subset, and normalizes it by the frequency of the same word in the entire set. It finds the relative importance of a word in the subset vs the whole. It can be used to determine if a word is more frequent in a specific episode than it is in the whole show, or if a word is used more frequently by a specific character than all the characters.\n",
    "\n",
    "Sentiment analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
